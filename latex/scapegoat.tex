\chapter{Árvores Scapegoat}
\chaplabel{scapegoat}

Neste capítulo, estudamos uma estrutura de dados de árvore binária de busca, a
#ScapegoatTree#.  Essa estrutura é baseada na ideia popular de que
quando algo sai errado, a primeira coisa que pessoas tendem a fazer 
é achar alguém para culpar (o bode expiatório, em inglês \emph{scapegoat}).
\index{scapegoat}%
\index{bode expiatório}%
Uma vez que culpa está estabelecida, podemos deixar que o bode expiatório resolva o problema. 

Uma #ScapegoatTree# se mantém balanceada usando \emph{operações de reconstrução parcial}
\index{reconstrução parcial}%
\index{árvore de busca binária!reconstrução parcial}%
Durante uma operação de reconstrução parcial, uma subárvore inteira
é desconstruída e reconstruída em uma subárvore perfeitamente balanceada.
Existem muitas forma de reconstrução de uma subárvore enraizada no nodo #u#
em uma árvore perfeitamente balanceada. Uma das mais simples é percorrer a subárvore de #u#, coletando todos seu nodos em um array, #a# e então recursivamente construir uma subárvore balanceada usando #a#.

Se fazemos
$#m#=#a.length#/2$,
então o elemento #a[m]# torna-se a raiz da nova subárvore,
$#a#[0],\ldots,#a#[#m#-1]$ é armazenada recursivamente na subárvore à esquerda 
e $#a#[#m#+1],\ldots,#a#[#a.length#-1]$ é armazenada na subárvore à direita. 

\codeimport{ods/ScapegoatTree.rebuild(u).packIntoArray(u,a,i).buildBalanced(a,i,ns)}
Uma chamada a 
#rebuild(u)# leva tempo $O(#size(u)#)$.  A subárvore resultante tem altura mínima;
não há árvore de menor altura com #size(u)# nodos.

\section{#ScapegoatTree#: Uma Árvore Binária de Busca com Reconstrução Parcial}
\seclabel{scapegoattree}

\index{ScapegoatTree@#ScapegoatTree#}%
Uma #ScapegoatTree# é uma #BinarySearchTree# que além de registrar o número #n# de nodos na árvore também mantém um contador #q# que mantém um limitante superior no número de nodos. 
\codeimport{ods/ScapegoatTree.q}
Durante todo seu uso, #n# e #q# seguem as seguintes desigualdades: 
\[
      #q#/2 \le  #n# \le #q#  \enspace .
\]
Além disso, uma 
#ScapegoatTree# tem altura logarítmica; e a altura da árvore scapegoat não excede: 
\begin{equation}
     \log_{3/2} #q# \le \log_{3/2} 2#n# < \log_{3/2} #n# + 2\enspace .
     \eqlabel{scapegoat-height}
\end{equation}
Mesmo com essa restrição, uma 
 #ScapegoatTree# pode parecer surpreendentemente desbalanceada. A árvore na \figref{scapegoat-example} tem $#q#=#n#=10$ e altura $5<\log_{3/2}10 \approx 5.679$.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/scapegoat-insert-1}
  \end{center}
  \caption[Uma ScapegoatTree]{Uma #ScapegoatTree# com 10 nodos e altura 5.}
  \figlabel{scapegoat-example}
\end{figure}

A implementação da operação #find(x)# em uma 
 #ScapegoatTree# é feita usando o algoritmo padrão para buscas em uma 
#BinarySearchTree#
(veja a \secref{binarysearchtree}).  Isso leva tempo proporcional à altura da árvore que, de acordo com a \myeqref{scapegoat-height}, é $O(\log #n#)$.

 Para implementar a operação 
#add(x)#, primeiramente incrementamos #n# e #q# e então usamos o algoritmo usual
para adicionar #x# a uma árvore binária de busca; buscamos por #x# e então
adicionamos uma nova filha #u# com 
$#u.x#=#x#$.
A esse ponto, podemos ter sorte e a profundidade de #u# pode não exceder
$\log_{3/2}#q#$. Se assim for, então deixamos a árvore como está e não fazemos mais nada. 

Infelizmente, em algumas vezes pode acontecer que
$#depth(u)# > \log_{3/2}
#q#$.  Nesse caso, precisamos reduzir essa altura. 
Isso não é nada demais; há somente um nodo, #u#, cuja profundidade excede
$\log_{3/2}
#q#$.  Para arrumar #u#, saímos de #u# para subir na árvore em busca de um \emph{bode expiatório} #w#. Esse bode expiatório é um nodo muito desbalanceado.
Ele tem a seguinte propriedade
\begin{equation}
   \frac{#size(w.child)#}{#size(w)#} > \frac{2}{3} \enspace ,
   \eqlabel{scapegoat}
\end{equation}
onde 
 #w.child# é o filho de #w#  no caminho da raiz a #u#. 
Iremos rapidamente provar que um bode expiatório existe.
Por agora, podemos assumir que ele existe.
Uma vez que encontramos o bode expiatório #w#, podemos completamente
destruir a subárvore enraizada em #w# e reconstruí-la em uma árvore binária
de busca perfeitamente balanceada.
Sabemos
da \myeqref{scapegoat} que mesmo antes da adição de #u#, a subárvore
de #w# não era uma árvore binária completa. 
Portanto, ao reconstruirmos #w#, a altura decresce por pelo menos 1 para que 
a altura de 
 #ScapegoatTree# seja novamente até $\log_{3/2}#q#$.

\codeimport{ods/ScapegoatTree.add(x)}

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics[scale=0.90909]{figs/scapegoat-insert-3} &
      \includegraphics[scale=0.90909]{figs/scapegoat-insert-4} 
    \end{tabular}
  \end{center}
  \caption[Adicionando à árvore scapegoat]{Inserindo 3.5 em uma #ScapegoatTree# aumenta sua altura para 6, o que viola a \myeqref{scapegoat-height} pois $6 > \log_{3/2} 11 \approx 5.914$.  Um bode expiatório é achado no nodo contendo 5.}
\end{figure}
Se ignorarmos o custo de achar o bode expiatório #w# e reconstruirmos 
a subárvore enraizada em #w#, então o tempo de execução de #add(x)# é
dominado pela busca inicial, o que leva
$O(\log #q#) = O(\log #n#)$ de tempo.
Iremos considerar o custo de encontrar o bode expiatório e de reconstrução
usando análise amortizada na seção a seguir.

A implementação de #remove(x)# em uma #ScapegoatTree# é muito simples.
Buscamos por #x# e o removemos usando o algoritmo usual para remover um
nodo de uma 
#BinarySearchTree#.  (Note que isso nunca aumenta a altura da árvore.) 
A seguir, decrementamos #n#, mas não alteramos #q#.
Finalmente, verificamos se 
$#q# > 2#n#$ e, caso positivo, então \emph{reconstruímos a árvore inteira} 
em uma árvore binária perfeitamente balanceada e atribuímos 
 $#q#=#n#$.
\codeimport{ods/ScapegoatTree.remove(x)}
Novamente, se ignorarmos o custo de recontrução, o tempo de execução da 
operação 
#remove(x)# é proporcional à altura da árvore, que é 
$O(\log #n#)$.

\subsection{Análise de Corretude e Tempo de Execução} 

Nesta seção, analisaremos a corretude e o tempo amortizado de operações
em uma #ScapegoatTree#.  Primeiro provamos a corretude ao mostrar que, quando a operação #add(x)# resulta em um nodo que viola a 
condição da \myeqref{scapegoat-height}, então sempre podemos achar um bode expiatório:

\begin{lem}
  Seja #u# um nodo de profundidade $h>\log_{3/2} #q#$ em uma #ScapegoatTree#.
  Então existe um nodo $#w#$ no caminho de #u# à raiz tal que 
  \[
     \frac{#size(w)#}{#size(parent(w))#} > 2/3 \enspace .
  \]
\end{lem}

\begin{proof}
  Suponha, para efeitos de contradição, que esse não é o caso, e 
  \[
     \frac{#size(w)#}{#size(parent(w))#} \le 2/3 \enspace .
  \]
  para todos os nodos #w# no caminho de #u# à raiz. Denote o caminho 
  da raiz a #u# como $#r#=#u#_0,\ldots,#u#_h=#u#$.  Então, temos 
  $#size(u#_0#)#=#n#$,
  $#size(u#_1#)#\le\frac{2}{3}#n#$, 
  $#size(u#_2#)#\le\frac{4}{9}#n#$ e, de modo mais geral, 
  \[
  #size(u#_i#)#\le\left(\frac{2}{3}\right)^i#n# \enspace .
  \]
  Mas isso resulta em uma contradição, pois
  $#size(u)#\ge 1$, portanto 
  \[
    1 \le #size(u)# \le \left(\frac{2}{3}\right)^h#n#
   < \left(\frac{2}{3}\right)^{\log_{3/2} #q#}#n#
   \le \left(\frac{2}{3}\right)^{\log_{3/2} #n#}#n#
   = \left(\frac{1}{#n#}\right) #n#
   = 1 \enspace . \qedhere
  \]
\end{proof}

A seguir analisamos as partes do tempo de execução que ainda não foram
levadas em conta.
Existem duas partes: o custo das chamadas a #size(u)# ao buscar por nodos
bodes expiatórios e o custo de chamadas a 
#rebuild(w)# quando encontramos um bode expiatório #w#.
O custo das chamadas a #size(u)# pode ser relacionado ao custo de chamadas
a #rebuild(w)# da seguinte forma:
\begin{lem}
Durante uma chamada a 
#add(x)# em uma #ScapegoatTree#, o custo de encontrar o bode expiatório #w# 
e reconstruir a subárvore enraizada em #w# é $O(#size(w)#)$.
\end{lem}

\begin{proof}
  O custo de reconstruir o nodo bode expiatório #w# uma vez que o achamos é 
$O(#size(w)#)$.  Ao buscar o nodo bode expiatório, chamamos #size(u)# em uma
sequência de nodos
$#u#_0,\ldots,#u#_k$ até que encontramos um bode expiatório 
$#u#_k=#w#$.  Porém, como $#u#_k$ é o primeiro nodo nessa sequência que é
  um bode expiatório, sabemos que 
\[
  #size(u#_{i}#)# < \frac{2}{3}#size(u#_{i+1}#)#
\]
para todo $i\in\{0,\ldots,k-2\}$.  Portanto, o custo de todas as chamadas a #size(u)# é
\begin{eqnarray*}
 O\left( \sum_{i=0}^k #size(u#_{k-i}#)# \right)
 &=& O\left(
  #size(u#_k#)# 
  + \sum_{i=0}^{k-1} #size(u#_{k-i-1}#)#
  \right) \\
 &=& O\left(
  #size(u#_k#)# 
  + \sum_{i=0}^{k-1} \left(\frac{2}{3}\right)^i#size(u#_{k}#)#
  \right) \\
&=& O\left(
  #size(u#_k#)#\left(1+ 
   \sum_{i=0}^{k-1} \left(\frac{2}{3}\right)^i
  \right)\right) \\
&=& O(#size(u#_k#)#) = O(#size(w)#) \enspace ,
\end{eqnarray*}
  onde a última linha segue do fato que a soma é uma série geométrica decrescente.
\end{proof}

Somente falta provar um limitante superior no custo de todas as chamadas a
#rebuild(u)# durante uma sequência de $m$ operações:

\begin{lem}\lemlabel{scapegoat-amortized}
  Iniciando com uma 
   #ScapegoatTree# vazia, uma sequência de $m$ operações #add(x)#
  e #remove(x)# faz com que as operações #rebuild(u) usem tempo #$O(m\log m)$.
\end{lem}

\begin{proof}
  Para provar isso, iremos usar um \emph{esquema de créditos}.
  \index{esquema de créditos}%
  Imaginamos que cada nodo guarda um número de créditos. Cada crédito
  pode pagar por alguma constante, $c$, unidades de tempo gastos na reconstrução.

  O esquema resulta provê um total de 
  $O(m\log m)$ créditos e toda chamada de #rebuild(u)# é paga com esses 
  créditos guardados em #u#.
Durante uma inserção ou deleção, cedemos um crédito a cada nodo no 
caminho ao nodo inserido, ou removido, #u#. 
Dessa maneira gastamos até 
  $\log_{3/2}#q#\le \log_{3/2}m$ créditos por operação. 
  Durante a remoção também guardamos um crédito adicional de reserva.
  Então, no total cedemos até 
   $O(m\log m)$ créditos. Tudo o que resta é mostrar que esses créditos 
   são suficientes para pagar por todas as chamadas a #rebuild(u)#.
Se chamarmos
   #rebuild(u)# durante uma inserção, é porque #u# é um bode expiatório.
   Suponha, sem perda de generalidade, que
  \[
    \frac{#size(u.left)#}{#size(u)#} > \frac{2}{3} \enspace .
  \]
  Usando o fato que 
  \[
    #size(u)# = 1 + #size(u.left)# + #size(u.right)# 
  \]
  deduzimos que 
  \[
    \frac{1}{2}#size(u.left)# > #size(u.right)#  \enspace 
  \]
  e portanto
  \[
    #size(u.left)# - #size(u.right)# > \frac{1}{2}#size(u.left)# >
    \frac{1}{3}#size(u)#  \enspace .
  \]
  Agora, a última vez que uma subárvore contendo #u# foi reconstruída (ou quando #u#
  foi inserido, se uma subárvore contendo #u# nunca foi reconstruída), temos
  \[
    #size(u.left)# - #size(u.right)# \le 1 \enspace .
  \]
  Portanto, o número de operações
  #add(x)# ou #remove(x)# que afetaram 
  #u.left# ou #u.right# desde então é pelo menos 
  \[
    \frac{1}{3}#size(u)# - 1 \enspace . 
  \]
  e há portanto pelo menos essa quantidade de créditos guardados em #u#
  que estão disponíveis para pagar pelo 
  $O(#size(u)#)$ de tempo que leva para chamar 
  #rebuild(u)#.

  Se chamamos 
  #rebuild(u)# durante uma remoção, é porque $#q# > 2#n#$.
  Nesse caso, temos 
  $#q#-#n#> #n#$ créditos guardados em uma reserva e os usamos
  para pagar pelo 
  $O(#n#)$ de tempo que leva para reconstruir a raiz. Isso completa a prova. 
\end{proof}

\subsection{Resumo}
O teorema a seguir resume o desempenho da estrutura de dados
 #ScapegoatTree#:

\begin{thm}\thmlabel{scapegoat}
  Uma #ScapegoatTree# implementa a interface #SSet#. Ignorando o custo
  de operações
  #rebuild(u)#, uma #ScapegoatTree# possui as operações
  #add(x)#, #remove(x)# e #find(x)# em tempo $O(\log #n#)$ por operação.
  
  Além disso, iniciando com uma 
  #ScapegoatTree# vazia, uma sequência de $m$ operações
  #add(x)# e #remove(x)# resulta em um tempo total $O(m\log m)$
  gasto nas chamadas a #rebuild(u)#.
\end{thm}

\section{Discussão e Exercícios}

O termo
 \emph{scapegoat tree} é atribuído a Galperin e Rivest \cite{gr93},
 que definiram e analizaram essas árvores. Porém, a mesma estrutura foi
 descoberta anteriormente por 
 \cite{a89,a99}, que as chamou de 
\emph{árvores balanceadas gerais (originalmente, em inglês, general balanced trees)}
\index{general balanced tree}%
\index{árvores balanceadas gerais}%
pois elas podem ter qualquer forma desde que a altura seja pequena. 

Experimentos com a implementação
 #ScapegoatTree# mostram que 
 ela costuma ser consideravelmente mais lenta que as outras implementações de #SSet# neste livro. 
 Isso pode ser surpreendente pois a altura é limitada a
\[
   \log_{3/2}#q# \approx 1.709\log #n# + O(1)
\] 
que é melhor que o comprimento esperado de um caminho de busca em uma
#Skiplist# e não muito longe de um em uma #Treap#.

A implementação pode ser otimizada ao armazenar os tamanhos das subárvores
explicitamente em cada nodo ou reutilizando tamanhos de subárvores previamente
computados (Exercícios~\ref{exc:scapegoat-quicksize}
e \ref{exc:scapegoat-explicitsize}).  Mesmo com essas otimizações,
sempre haverão sequências de operações 
#add(x)# e #delete(x)# para as quais uma 
 #ScapegoatTree# leva mais tempo que outras implementações da #SSet#.

Essa diferença em desempenho é devido ao fato que, diferentemente de
outras implementações #SSet# discutidas neste livro, uma 
 #ScapegoatTree# pode gastar muito tempo se reestruturando. 
O \excref{scapegoat-nlogn} pede que você prove que existem sequências de #n# 
operações em que uma #ScapegoatTree# irá gastar 
 $#n#\log #n#$ de tempo em chamadas a #rebuild(u)#.
Isso contrasta a outras implementações #SSet# discutidas neste livro, que fazem somente 
$O(#n#)$ mudanças estruturais durante uma sequência de 
#n# operações. Isto é, infelizmente, uma consequência necessária do fato que 
uma #ScapegoatTree# faz sua restruturação usando chamadas a  
#rebuild(u)# \cite{d90}.

Apesar de seu desempenho relativamente ruim, há aplicações em que uma
#ScapegoatTree# pode ser a escolha certa. 
Isso ocorre quando há dados adicionais associados a nodos que não
podem ser atualizados em tempo constante quando uma rotação é realizada
mas que podem ser atualizados em uma operação #rebuild(u)#.
Nesses casos, a 
#ScapegoatTree# e outras estruturas similares baseadas em reconstrução parcial podem
funcionar bem. Um exemplo de tal aplicação é esboçado no \excref{list-order-maintenance}.

\begin{exc}
Simule a adição dos valores  1.5 e depois 1.6 na 
  #ScapegoatTree# na \figref{scapegoat-example}.
\end{exc}

\begin{exc}
  Ilustre o que acontece quando a sequência 
   $1,5,2,4,3$ é adicionada a uma 
  #ScapegoatTree# vazia e mostre onde os créditos descritos na prova 
  do \lemref{scapegoat-amortized} vão e como eles são usados durante
   essa sequência de adições. 
\end{exc}

\begin{exc}\exclabel{scapegoat-nlogn}
  Mostre que, se começarmos com uma 
  #ScapegoatTree# vazia e chamarmos #add(x)# para
  $#x#=1,2,3,\ldots,#n#$, então o tempo total gasto em chamadas a 
  #rebuild(u)# é pelo menos $c#n#\log #n#$ para alguma constante $c>0$.
\end{exc}

\begin{exc}
  A #ScapegoatTree#, conforme descrita neste capítulo, garante que o 
  comprimento do caminho de busca não excede
   $\log_{3/2}#q#$.
  \begin{enumerate}
    \item  Projete, analise e implemente uma versão modificada de 
      #ScapegoatTree# onde o comprimento do caminho de busca que não excede 
      $\log_{#b#} #q#$, onde #b# é um parâmetro com $1<#b#<2$.
    \item O que sua análise e experimentos dizem sobre o custo amortizado de 
      #find(x)#, #add(x)# e #remove(x)# como uma função de #n# e #b#?
  \end{enumerate}
\end{exc}

\begin{exc}\exclabel{scapegoat-quicksize}
Modifique o método #add(x)# da #ScapegoatTree# para que não gaste 
tempo recomputando os tamanhos das subárvores que foram
anteriormente computados. Isso é possível porque quando o método 
  quer computar #size(w)#, ele já computou #size(w.left)#
  ou #size(w.right)#.  Compare o desempenho de sua
  implementação modificada com a implementação fornecida neste livro. 
\end{exc}

\begin{exc}\exclabel{scapegoat-explicitsize}
  Implemente uma segunda versão da estrutura de dados #ScapegoatTree# 
  que explicitamente guarda e mantém os tamanhos da subárvore enraizada
  em cada nodo. Compare o desempenho da implementação resultante
  com a #ScapegoatTree# original assim como a implementação feita para o
  \excref{scapegoat-quicksize}.
\end{exc}

\begin{exc}
  Reimplemente o método #rebuild(u)# discutido no começo desse capítulo para que não necessite do uso de um array para guardar os nodos da subárvore sendo reconstruída.
  Em vez disso, deve-se usar recursão primeiro para conectar os nodos em uma lista ligada e então converter essa lista ligada em uma árvore binária perfeitamente balanceada. (Existem implementações recursivas muito elegantes de ambos os passos.)
\end{exc}

\begin{exc}
  \index{WeightBalancedTree@#WeightBalancedTree#}%
  Analise e implemente uma #WeightBalancedTree#. Essa é uma árvore em que cada nodo #u#, exceto a raiz, mantém a \emph{invariante de balanceamento} 
   $#size(u)# \le (2/3)#size(u.parent)#$.  As operações #add(x)# e
  #remove(x)# são idênticas às operações padrões da #BinarySearchTree#,
  exceto que toda vez que a invariante de balanceamento é violada
  em um nodo #u#, a subárvore enraizada em #u.parent# é reconstruída.
A sua análise deve mostrar que operações em uma 
   #WeightBalancedTree# rodam em tempo amortizado 
$O(\log#n#)$.
\end{exc}

\begin{exc}
  \index{CountdownTree@#CountdownTree#}%
  Analise e implemente uma
   #CountdownTree#.  Em uma #CountdownTree# cada nodo #u# mantém um
   \emph{timer} #u.t#.  As operações #add(x)# e #remove(x)#
  são exatamente as mesmas que em uma #BinarySearchTree# padrão
  exceto que, sempre que uma dessas operações afetam a subárvore #u#
  a variável #u.t# é decrementada. Quando 
   $#u.t#=0$ a subárvore inteira enraizada em #u#
   é reconstruída em uma árvore binária de busca perfeitamente balanceada.
   Quando um nodo #u# estiver envolvido em uma operação de reconstrução (porque #u# foi reconstruída ou um dos ancestrais de #u# foi reconstruído) #u.t# é reiniciada a
  $#size(u)#/3$.

  Sua análise deve mostrar que as operações em uma 
   #CountdownTree# roda em tempo amortizado 
  $O(\log #n#)$.  (Dica: primeiro mostre que cada nodo #u# satisfaz 
  alguma versão de uma invariante de balanceamento.)
\end{exc}

\begin{exc}
  \index{DynamiteTree@#DynamiteTree#}%
  Analise e implemente uma #DynamiteTree#.  Em uma #DynamiteTree# cada nodo 
  #u# registra o tamanho da subárvore enraizada em #u# em uma variável
  #u.size#.  As operações #add(x)# e #remove(x)# são exatamente as mesmas que em uma 
  #BinarySearchTree# padrão exceto que, sempre que uma dessas operações afeta uma subárvore de um nodo #u#, esse nodo \emph{explode} com probabilidade 
  $1/#u.size#$.  Quando #u# explode, sua subárvore inteira é reconstruída
  em uma árvore binária de busca perfeitamente balanceada.
  A sua análise deve mostrar que operações em uma
   #DynamiteTree# rodam em tempo esperado $O(\log #n#)$. 
\end{exc}
 

\begin{exc}\exclabel{list-order-maintenance}
  \index{Sequence@#Sequence#}%
  Projete e implemente uma estrutura de dados
  #Sequence# que mantém uma sequência (lista) de elementos. 
  Ela suporta as seguintes operações:
  \begin{itemize}
    \item #addAfter(e)#: adiciona um novo elemento após o elemento #e# na sequência. Retorna o elemento adicionado. (Se #e# for null, o novo elemento é adicionado no início da sequência.)
    \item #remove(e)#: Remove #e# da sequência. 
    \item #testBefore(e1,e2)#: retorna #true# se e somente se #e1# vem antes de 
    #e2# na sequência.
  \end{itemize}
  As primeiras duas operações devem rodar em tempo amortizado
  $O(\log #n#)$. A terceira operação deve rodar em tempo constante.

  A estrutura de dados 
  #Sequence# pode ser implementada na mesma ordem que ocorrem na sequência.
  Para implementar #testBefore(e1,e2)# em tempo constante,
  cada elemento #e# é marcado com um inteiro que codifica o caminho da raiz até #e#.
  Dessa forma, 
   #testBefore(e1,e2)# pode ser implementada pela comparação das marcações de #e1# e #e2#. 
\end{exc}

