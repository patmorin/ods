\chapter{Árvores Binárias}
\chaplabel{binarytrees}

Este capítulo apresenta uma das estruturas mais fundamentais na Ciência
da Computação: as árvores binárias. O uso da palavra
\emph{árvore}
\index{árvore}%
\index{árvore!binária}%
\index{árvore binária}%
vem do fato que, quando as desenhamos, elas frequentemente lembram árvores 
encontradas em uma floresta. Existem muitos jeitos de definir 
árvores binárias. Matematicamente, uma \emph{árvore binária} é um grafo finito, conectado, não direcionado, sem ciclos e sem nenhum vértice de grau maior que três.

Para a maioria das aplicações em Ciência da Computação, árvores binárias são \emph{enraizadas}:
\index{árvore!enraizada}%
\index{árvore enraizada}%
Um nodo especial #r# de grau até dois é chamado de \emph{raiz} da árvore.
Para todo nodo
$#u#\neq #r#$, o segundo nodo no caminho de 
#u# a #r# é chamado de \emph{pai} de #u#.
\index{pai}%
Cada um dos outros nodos adjacentes a #u# é chamado de \emph{filho}
\index{filho} de #u#. A maior parte das árvores binárias que 
estamos interessados são 
\emph{ordenadas},
\index{árvore ordenada}%
\index{árvore!ordenada}%
então diferenciamos entre o \emph{filho à esquerda} e \emph{filho à direita} de #u#.
\index{filho à esquerda}%
\index{filho!esquerda}%
\index{filho à direita}%
\index{filho!direita}%

Em desenhos, árvores binárias são tipicamente desenhadas de ponta-cabeça, 
com a raiz no topo do desenho e os filhos à esquerda e direita
respectivamente dados pelas posições à esquerda e direita no desenho
(\figref{bintree-orientation}).  Por exemplo, a \figref{binary-tree}.a mostra
uma árvore binária com nove nodos. 

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/bintree-traverse-1} 
  \end{center}
  \caption[Pai, filho à esquerda e filho à direita]{O pai, filho à esquerda e filho à direita do nodo #u# em uma #BinaryTree#.}
  \figlabel{bintree-orientation}
\end{figure}


\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics[width=\HalfScaleIfNeeded]{figs/bintree-1} &
      \includegraphics[width=\HalfScaleIfNeeded]{figs/bintree-2} \\
      (a) & (b)
    \end{tabular}
  \end{center}
  \caption{Uma árvore binária com (a)~nove nodos reais (ou internos) e (b)~dez nodos externos.}
  \figlabel{binary-tree}
\end{figure}

Devido à importância de árvores binárias, uma certa terminologia se desenvolveu
para elas: a \emph{profundidade}
\index{profundidade}%
de um nodo #u#, em uma árvore binária é o comprimento do caminho de #u# à raiz da árvore. Se um nodo #w# está no caminho de #u# para #r#, então #w# é chamado de \emph{ancestral} 
\index{ancestral}%
de #u# e #u# um \emph{descendente}
\index{descendente}%
de #w#.  A \emph{subárvore} de um nodo 
, #u#, é a árvore binária que é enraizada em #u# e contém todos os descendentes de #u#. A \emph{altura}
\index{altura!em uma árvore} de um nodo, #u#, é o comprimento do caminho mais
longo de #u# e um de seus descendentes. A \emph{altura} de 
\index{altura!de uma árvore}%
uma árvore é a altura de sua raiz.
Um nodo #u# é uma \emph{folha} se não tem filhos.

Ás vezes consideramos que árvores possuem \emph{nodos externos}.
Qualquer nodo que não tem filho à esquerda tem um nodo externo como filho à
esquerda e, de modo similar, um nodo que não tem filho à direita tem um nodo externo como filho à direita (ver a \figref{binary-tree}.b).  
É fácil verificar, por indução, que uma árvore binária 
com $#n#\ge 1$ nodos reais tem $#n#+1$ nodos externos.

\section{#BinaryTree#: Uma Árvore Binária Básica}

\index{BinaryTree@#BinaryTree#}%
O jeito mais simples de representar um nodo #u# em uma árvore binária
é explicitamente guardar os 
(no máximo três) vizinhos de #u#\notpcode{:}\pcodeonly{.}
\javaimport{ods/BinaryTree.BTNode<Node}
\cppimport{ods/BinaryTree.BTNode}
Se um desses três vizinhos não estiver presente, o atribuímos a #nil#.
Desse jeito, ambos nodos externos da árvore e o pai da raiz correspondem ao
valor #nil#.

A própria árvore binária pode então ser representada por uma 
\javaonly{referência}\cpponly{ponteiro}\pcodeonly{referência} ao seu nodo raiz, #r#:
\codeimport{ods/BinaryTree.r}

Podemos computar a profundidade de um nodo #u# em uma árvore binária contando o
número de passos do caminho de #u# à raiz:
\codeimport{ods/BinaryTree.depth(u)}


\subsection{Algoritmos recursivos}

\index{algoritmo recursivo}%
Usar algoritmos recursivos facilita a computação de fatos sobre árvores 
binárias. Por exemplo, para computar o tamanho de (número de nodos)
uma árvore binária enraizada no nodo #u#, recursivamente computamos
os tamanhos de duas subárvores enraizadas aos filhos de #u#, somar esses tamanhos, e somar um:

\codeimport{ods/BinaryTree.size(u)}

Para computar a altura de um nodo 
#u#, podemos computar a altura das duas subárvores de #u#, obter o máximo e somar um:

\codeimport{ods/BinaryTree.height(u)}

\subsection{Percorrendo Árvores Binárias}
\seclabel{bintree:traversal}

\index{travessia!de uma árvore binária}%
\index{travessia de árvore}%
\index{travessia de árvore binária}%
Os dois algoritmos da seção anterior usam recursão para visitar
todos os nodos em uma árvore binária. Cada um deles visita os nodos
da árvore binária na mesma ordem que o código a seguir:
\codeimport{ods/BinaryTree.traverse(u)}

Usar recursão desse jeito resulta em um código bem curto e simples mas
pode também ser problemático. A profundidade máxima da recursão é dada
pela profundidade máxima de um nodo na árvore binária, i.e., a altura
da árvore.

Se a altura da árvore é grande, então essa recursão pode muito bem usar 
mais espaço de pilha de memória do que está disponível, causando um erro.

Para percorrer uma árvore binária sem recursão, você pode usar um algoritmo 
que usa a informação de onde veio para determinar para onde irá a seguir.
Veja a \figref{bintree-traverse}.  
Ao chegarmos no nodo #u# a partir de #u.parent# então o próximo passo
é visitar #u.left#. Se chegarmos em #u# vindo de #u.right#, então
terminamos a visita da subárvore de #u# e retornamos a #u.parent#.
O código a seguir implementa essa ideia, incluindo o tratamento dos
casos onde #u.left#, #u.right# ou #u.parent# sejam #nil#:
\codeimport{ods/BinaryTree.traverse2()}

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics[scale=0.90909]{figs/bintree-traverse-2}
      \includegraphics[scale=0.90909]{figs/bintree-3}
    \end{tabular}
  \end{center}
  \caption[Percorrendo uma BinaryTree]{Os três casos que ocorrem no nodo #u# ao percorrer uma árvore binária não recursiva e o caminho resultante na árvore.}
  \figlabel{bintree-traverse}
\end{figure}

Os mesmos fatos que podem ser computados com algoritmos recursivos também podem
ser obtidos dessa maneira, sem recursão. Por exemplo, para computar o tamanho 
de uma árvore mantemos um contador #n# e o incrementamos toda vez que visitarmos um nodo pela primeira vez:
\codeimport{ods/BinaryTree.size2()}

Em algumas implementações de árvores binárias, o campo #parent# é não usado.
Quando esse é o caso, uma implementação não recursiva ainda é possível,
mas a implementação tem que usar uma 
#List# (ou #Stack#) para registrar o caminho do nodo atual à raiz.

Um tipo especial de percurso que não se adequa ao padrão das funções acima é a
\emph{travessia em largura} ou, em inglês, \emph{breadth-first traversal}.
\index{travessia em largura}
\index{breadth-first traversal}%
\index{traversal!breadth-first}%
Em uma travessia em largura, os nodos são visitados nível-a-nível iniciando na raiz e descendo, visitando os nodos a cada nível da esquerda à direita (ver
\figref{bintree-bfs}). Isso é similar à forma que leríamos uma página de texto em inglês. Travessia em largura é implementada usando uma queue 
, #q#, que inicialmente contém somente a raiz #r#. A cada passo, 
extraímos o próximo nodo #u# de #q#, processamos #u# e adicionamos #u.left#
e #u.right# (se eles forem não-#nil#) a #q#:
\codeimport{ods/BinaryTree.bfTraverse()}

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/bintree-4}
  \end{center}
  \caption{Durante uma travessia em largura, os nodos de uma árvore binária são visitados um nível por vez e da esquerda para a direita a cada nível.}
  \figlabel{bintree-bfs}
\end{figure}


\section{#BinarySearchTree#: Uma Árvore Binária de Busca Desbalanceada} 
\seclabel{binarysearchtree}

\index{BinarySearchTree@#BinarySearchTree#}%
\index{binary search tree}%
\index{árvore binária de busca}
\index{binary tree!search}%
Uma 
#BinarySearchTree# é um tipo especial de árvore binária em que cada nodo #u# também guarda um valor de dado #u.x# a partir de alguma ordem total.
Os valores de dados em uma árvore binária de busca obedecem a \emph{propriedade da árvore binária de busca}:
\index{propriedade da árvore binária de busca}%
Para um nodo #u#, todo valor guardado na subárvore enraizada em #u.left#
é menor que #u.x# e todo valor de dado guardado em uma subárvore enraizada 
em #u.right# é maior que #u.x#. Um exemplo de uma
 #BinarySearchTree# é mostrado em \figref{bst}.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/bst-example}
    %\includegraphics[scale=0.90909]{figs/binary-tree-4}
  \end{center}
  \caption{Uma árvore binária de busca.}
  \figlabel{bst}
\end{figure}


\subsection{Busca}

\index{caminho de busca!em uma árvore binária de busca}%
A propriedade da árvore binária de busca é extremamente útil porque 
nos permite rapidamente localizar um valor #x# em uma árvore binária de busca.
Para fazer isso, iniciamos procurando por #x# na raiz #r#. Ao examinar um nodo
#u#, há três casos:
\begin{enumerate}
\item Se $#x#< #u.x#$, então a busca segue para #u.left#;
\item Se $#x#> #u.x#$, então a busca segue para #u.right#;
\item Se $#x#= #u.x#$, então achamos o nodo #u# contendo #x#.
\end{enumerate}
A busca termina quando o Caso~3 ocorre ou quando #u=nil#. 
No Caso~3, achamos #x#. Quando #u=nil#, concluímos que #x# não está
na árvore binária de busca.
\codeimport{ods/BinarySearchTree.findEQ(x)}

Dois exemplos de buscas em uma árvore binária de busca são mostrados
em 
\figref{bst-search}.  Conforme o segundo exemplo mostra, mesmo se não
acharmos $x$ no último nodo #u#, no qual ocorre o Caso~1, vemos que #u.x# é
o menor valor na árvore que é maior que #x#. 
De modo similar, o último nodo no qual Caso~2 ocorreu contém o maior valor na
árvore que é menor que #x#. Portanto, ao registrar o último nodo #z# no qual Caso~1 ocorre, uma 
 #BinarySearchTree# pode implementar a operação 
#find(x)# que retorna o menor valor guardado na árvore que é maior que ou igual a #x#: 
\codeimport{ods/BinarySearchTree.find(x)}

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
    \includegraphics[width=\HalfScaleIfNeeded]{figs/bst-example-2} &
    \includegraphics[width=\HalfScaleIfNeeded]{figs/bst-example-3} \\
    (a) & (b)
    \end{tabular}
  \end{center}
  \caption{Um exemplo de (a)~uma busca bem sucedida (por $6$) e (b)~uma busca mal sucedida (por $10$) em uma árvore binária de busca.}
  \figlabel{bst-search}
\end{figure}


\subsection{Adição}

Para adicionar um novo valor #x# a uma 
#BinarySearchTree#, primeiro buscamos por #x#. 
Se acharmos, então não há necessidade de o inserirmos. Por outro lado,
guardamos #x# na folha do último nodo #p# encontrado durante a busca
por #x#. Se um novo nodo está no filho à esquerda ou à direita de #p# depende
no resultado da comparação entre 
 #x# e #p.x#.
\codeimport{ods/BinarySearchTree.add(x)}
\codeimport{ods/BinarySearchTree.findLast(x)}
\codeimport{ods/BinarySearchTree.addChild(p,u)}
Um exemplo é mostrado em 
\figref{bst-insert}. A parte que mais gasta tempo desse processo é a busca inicial por #x#, que leva um tempo proporcional à altura do novo nodo #u#.
No pior caso, isso é igual à altura da #BinarySearchTree#.


\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
    \includegraphics[width=\HalfScaleIfNeeded]{figs/bst-example-4} &
    \includegraphics[width=\HalfScaleIfNeeded]{figs/bst-example-5} 
    \end{tabular}
  \end{center}
  \caption{Inserindo o valor $8.5$ em uma árvore binária de busca.} 
  \figlabel{bst-insert}
\end{figure}


\subsection{Remoção}

Remover um valor guardado em um nodo #u# de uma
#BinarySearchTree# é um pouco mais difícil. 
Se #u# for uma folha, então podemos simplesmente desconectar #u# de seu pai.

Melhor ainda, se #u# tiver um único filho, então podemos destacar #u#
da árvore fazendo 
#u.parent# adotar o filho de #u# (veja a
\figref{bst-splice}):
\codeimport{ods/BinarySearchTree.splice(u)}

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/bst-splice}
  \end{center}
  \caption{Remover uma folha ($6$) ou um nodo com somente um filho ($9$) é fácil.}
  \figlabel{bst-splice}
\end{figure}

A situação complica quando #u# tem dois filhos. Nesse caso,
o mais simples a fazer é achar um nodo #w#, que seja menor que 
os dois filhos e tal que #w.x# possa substituir #u.x#.
Para manter a propriedade da árvore de busca binária, o valor
#w.x# deveria ser próximo ao valor de #u.x#. Por exemplo, escolher um #w# tal que #w.x# é o menor valor maior que #u.x# funcionaria.
Achar o nodo #w# é fácil; é o menor valor na subárvore enraizada em #u.right#.
Esse nodo pode ser facilmente removido porque não tem filho à esquerda
(veja a \figref{bst-remove}).
\javaimport{ods/BinarySearchTree.remove(u)}
\cppimport{ods/BinarySearchTree.remove(u)}
\pcodeimport{ods/BinarySearchTree.remove_node(u)}

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
    \includegraphics[width=\HalfScaleIfNeeded]{figs/bst-delete-1}
    \includegraphics[width=\HalfScaleIfNeeded]{figs/bst-delete-2}
    \end{tabular}
  \end{center}
  \caption[Removendo de uma BinarySearchTree]{A remoção de um valor ($11$) de um nodo, #u#, com dois filhos é feita pela substituição do valor de #u# com o menor valor na subárvore à direita de #u#.} 
  \figlabel{bst-remove}
\end{figure}

\subsection{Resumo}

As operações
#find(x)#, #add(x)# e #remove(x)# em uma 
#BinarySearchTree# envolvem seguir um caminho da raiz da árvore a algum nodo. 
Sem saber mais sobre o formato da árvore é difícil dizer algo sobre o comprimento desse caminho, exceto que é menor que #n#, o número de nodos na árvore.
A seguinte teorema (pouco impressionante) resume o desempenho da estrutura de dados 
#BinarySearchTree#:

\begin{thm}\thmlabel{bst}
  #BinarySearchTree# implementa a interface #SSet# interface e aceita
  as operações #add(x)#, #remove(x)#
  e #find(x)# em $O(#n#)$ de tempo por operação.
\end{thm}

O \thmref{bst} demonstra um desempenho ruim em comparação ao \thmref{skiplist}, que mostra que 
uma estrutura #SkiplistSSet# implementa a interface #SSet# 
com $O(\log #n#)$ de tempo esperado por operação. O problema com a estrutura 
#BinarySearchTree# é que pode se tornar \emph{desbalanceada}.
Em vez de parecer como uma árvore na \figref{bst}, ela pode parecer 
como uma longa cadeia de 
#n# nodos, todos exceto o último com exatamente um filho. 

Existem várias maneiras de evitar árvores binárias desbalanceadas, todas elas
levam a estruturas de dados que tem 
 operações que executam com $O(\log #n#)$ de tempo. 
No \chapref{rbs} mostramos como operações com $O(\log #n#)$ de tempo 
\emph{esperado} podem ser obtidas com randomização. 
No \chapref{scapegoat} mostramos como operações que executam em $O(\log #n#)$ de tempo \emph{amortizado} podem ser obtidas com operações de reconstrução parcial.
No \chapref{redblack} mostramos como operações que executam em $O(\log #n#)$ de tempo no \emph{pior caso} podem ser obtidas ao simular uma árvore que não é binária: uma árvore cujos nodos podem ter até quatro filhos.

\section{Discussão e Exercícios}

Árvores binárias têm sido usadas para modelar relações por milhares
de anos. Uma razão para isso é que árvores binárias naturalmente  
modelam árvores genealógicas (e de pedigree).
\index{árvores genealógicas}%
\index{árvores de pedigree}%
Essas árvores genealógicas em que a raiz é uma pessoa, os filhos à esquerda e à direita são os pais de uma pessoa e assim por diante, recursivamente.
Em séculos mais recentes, árvores binárias também tem sido usadas para modelar
espécies de árvores 
\index{espécies de árvores}%
em biologia, onde as folhas da árvore representam uma espécie existente e nodos internos
de uma árvore representam 
\emph{eventos de especiação}
\index{evento de especiação} no qual duas populações de uma única espécie evoluem em duas espécies distintas. 

Árvores binárias de busca parecem terem sido descobertas independentemente
por vários grupos na década de 1950
\cite[Section~6.2.2]{k97v3}.  Referências adicionais a tipos específicos 
de árvores binárias de busca são fornecidas nos capítulos a seguir.

Ao implementar uma árvore binária desde o início, várias decisões de projeto devem ser feitas. Uma delas é se nodos devem guardar um ponteiro para o seu pai.

Se a maior parte das operações simplesmente seguirem um caminho da raiz para a folha, então ponteiros para nodos-pai são desnecessários, desperdício de memória e uma potencial fonte de erros de codificação. Por outro lado, a falta de ponteiros para
nodos-pai significa que travessias em árvores devem serem feitas recursivamente ou com o uso de uma stack explícita.

Alguns outros métodos (como inserir ou remover em alguns tipos de árvores binárias de busca balanceadas) também podem ficar mais complicados sem o uso de ponteiros para nodo-pai.

Outra decisão de projeto refere-se a como guardar os ponteiros pai, filho à esquerda e 
filho à direita em um nodo. Na implementação dada aqui, esses
ponteiros são guardados como variáveis separadas.
Outra opção é guardá-los em um array #p# de tamanho 3, tal que 
#u.p[0]# é o filho à esquerda de #u#, 
#u.p[1]# é o filho à direita de #u# e
#u.p[2]# é o pai de #u#.
Usando um array dessa forma implica que algumas sequências de comandos #if#
podem ser simplificadas em expressões algébricas.

Um exemplo dessa simplificação ocorre durante uma travessia de árvore.
Se uma travessia chega em um nodo 
#u# a partir de #u.p[i]#, então o próximo nodo na travessia é 
$#u.p#[(#i#+1)\bmod 3]$.  Exemplos similares ocorrem quando há simetria esquerda-direita. 
Por exemplo, o irmão de #u.p[i]# é
$#u.p#[(#i#+1)\bmod 2]$.  Esse truque funciona se #u.p[i]# é um filho à esquerda
($#i#=0$) ou um filho à direita ($#i#=1$) de #u#. 
Em alguns casos, isso significa que algum código complicado que de outra maneira 
precisaria ter uma versão para atuar na esquerda e uma versão para atuar na direita
poderia ser escritos apenas uma vez.
Como exemplo, veja os métodos
#rotateLeft(u)# e #rotateRight(u)# na página~\pageref{page:rotations}.

\begin{exc}
  Prove que uma árvore binária com $#n#\ge 1$ nodos tem $#n#-1$ arestas.
\end{exc}

\begin{exc}
  Prove que uma árvore binária com $#n#\ge 1$ nodos reais tem $#n#+1$
  nodos externos.
\end{exc}

\begin{exc}
  Prove que, se uma árvore binária, $T$, tem pelo menos uma folha, então
  (a)~a raiz de $T$ tem no máximo um filho ou (b)~$T$ tem mais de uma folha.
\end{exc}

\begin{exc}
  Implemente um método não recursivo, #size2(u)#, que computa o tamanho da subárvore enraizada no nodo #u#.
\end{exc}

\begin{exc}
  Escreva um método não recursivo #height2(u)# que computa a altura do nodo 
  #u# em uma #BinaryTree#.
\end{exc}

\begin{exc}
  Uma árvore binária é 
  \emph{balanceada no tamanho}
  \index{balanceada no tamanho}%
  \index{árvore binária de busca!balanceada no tamanho}%
  se, para todo nodo #u#, o tamanho das subárvores enraizadas em 
   #u.left# e #u.right# diferem em no máximo uma unidade. 
   Escreva #isBalanced()#, um método recursivo que testa se uma árvore
   binária é balanceada. O seu método deve rodar em 
  $O(#n#)$ de tempo.  (Teste o seu código em algumas árvores
  maiores com diferentes formas; é fácil escrever um método que usa bem mais
  de $O(#n#)$ de tempo.) 
\end{exc}

\index{travessia!pré-ordem}%
\index{travessia!pós-ordem}%
\index{travessia!em ordem}%
\index{travessia pré-ordem}%
\index{travessia em ordem}%
\index{travessia pos ordem}%
Uma travessia em \emph{pré-ordem} (em inglês, \emph{pre-order} traversal) de uma árvore binária é uma travessia que visita cada nodo #u# antes de qualquer de seus filhos.
Uma travessia em ordem (em inglês, \emph{in-order} traversal) visita #u#
depois de visitar todos os nodos na subárvore à esquerda de #u# mas antes de visitar qualquer nodo na subárvore à direita de #u#.

Um travessia em \emph{pós-ordem} (em inglês, \emph{post-order})
visita #u# somente após visitar todos os outros nodos na subárvore de #u#.
A numeração pré/em/pós-ordem de uma árvore marca os nodos de uma árvore com os
inteiros
$0,\ldots,#n#-1$ na ordem em que são visitados por uma travessia 
em pré/em/pós-ordem. Para um exemplo, veja \figref{binarytree-numbering}.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/binarytree-numbering-1}
    \includegraphics[scale=0.90909]{figs/binarytree-numbering-2} \\[2ex]
    \includegraphics[scale=0.90909]{figs/binarytree-numbering-3}
  \end{center}
  \caption{Numerações pré-ordem, pós-ordem e em ordem de uma árvore binária.}
  \figlabel{binarytree-numbering}
\end{figure}

\begin{exc}
  \index{numeração!pré-ordem}%
  \index{numeração!pós-ordem}%
  \index{numeração!em-ordem}%
  \index{numeração pré-ordem}%
  \index{numeração pós-ordem}%
  \index{numeração em-ordem} %
  Crie uma subclasse de 
   #BinaryTree# cujos nodos tem campos para guardar numerações pré/in/pós-ordem.
Escreva métodos recursivos 
  #preOrderNumber()#, #inOrderNumber()# e  #postOrderNumbers()# que atribui
  esses números corretamente. Cada um desses métodos deve rodar em $O(#n#)$ de tempo.
\end{exc}

\begin{exc}\exclabel{tree-traversal}
  Implemente as funções não recursivas #nextPreOrder(u)#, #nextInOrder(u)# e 
  #nextPostOrder(u)# que retornam o nodo que segue #u#  em uma travessia pré/em/pós-ordem, respectivamente. Essas funções devem levar tempo constante amortizado; se iniciarmos em qualquer nodo #u# e chamarmos uma dessas funções e atribuirmos o valor a #u# até 
  $#u#=#null#$, então o custo de todas essas chamadas deve ser 
  $O(#n#)$.
\end{exc}

\begin{exc}
  Suponha que recebemos uma árvore binária com numerações pré/em/pós ordem atribuídas aos nodos. Mostre como esses números podem ser usados para responder cada uma das perguntas a seguir em tempo constante:
  \begin{enumerate}
    \item Dado um nodo #u#, determine o tamanho da subárvore enraizada em #u#.
    \item Dado um nodo #u#, determine a profundidade de #u#.
    \item Dados dois nodos #u# e #w#, determine se #u# é um ancestral de #w#.
  \end{enumerate}
\end{exc}

\begin{exc}
  Suponha que você recebeu uma lista de nodos com numerações pré/em-ordem atribuídas. Prove que existe no máximo uma árvore possível com essas numerações
  e mostre como construí-la.
\end{exc}

\begin{exc}
  Mostre que o tamanho de qualquer árvore binária em #n# nodos pode ser representado
  usando no máximo 
  $2(#n#-1)$ bits.  (Dicas: pense em gravar o que acontece durante uma travessia em então repetir essa gravação para reconstruir a árvore.) 
\end{exc}

\begin{exc}
  Ilustre o que acontece quando adicionamos os valores $3.5$ e então $4.5$ à árvore binária de busca em \figref{bst}.
\end{exc}

\begin{exc}
  Ilustre o que acontece ao removermos os valores $3$ e então $5$ da árvore binária de busca em \figref{bst}.
\end{exc}

\begin{exc}
  Implemente um método na #BinarySearchTree# chamado de #getLE(x)#
  que retorna uma lista de todos os itens na árvore que são menores que
  ou iguais a #x#. O tempo de execução do seu método deve ser 
  $O(#n#'+#h#)$ onde $#n#'$ é o número de itens menores que ou iguais a #x# e #h#
  é a altura da árvore.
\end{exc}

\begin{exc}
  Descreva como adicionar elementos $\{1,\ldots,#n#\}$ a uma 
  #BinarySearchTree# inicialmente vazia de tal forma que a árvore resultante tem altura 
$#n#-1$.  Quantas formas existem para fazer isso? 
\end{exc}

\begin{exc}
  Se tivermos uma 
  #BinarySearchTree# e realizarmos as operações #add(x)# seguidas de #remove(x)#
  (com o mesmo valor de #x#) retornamos à árvore original?
\end{exc}

\begin{exc}
  É possível uma operação #remove(x)# aumentar a altura de um nodo em uma 
  #BinarySearchTree#?  Se sim, em quanto? 
\end{exc}

\begin{exc}
  Uma operação
  #add(x)# consegue aumentar a altura de um nodo em uma 
  #BinarySearchTree#?  Ela pode aumentar a altura da árvore? Se sim, em quanto? 
\end{exc}

\begin{exc}
  Projete e implemente uma versão da 
  #BinarySearchTree# em que cada nodo 
  #u#, mantém valores #u.size# (o tamanho da subárvore enraizada em #u#),
  #u.depth# (a profundidade de #u#) e #u.height# (a altura da subárvore enraizada de #u#). 

  Esses valores devem ser mantidos, mesmo durante chamadas às operações  #add(x)#
  e #remove(x)#, mas isso não deve aumentar o custo dessas operações em mais do que um fator constante. 
\end{exc}
