\chapter{Grafos}
\chaplabel{graphs}

%\textbf{Warning to the Reader:} This chapter is still being actively
%developed, meaning that the code has not been thoroughly tested and/or
%the text has not be carefully proofread.

Neste capítulo, estudamos duas representações de grafos e algoritmos
básicos que usam essas representações.

Matematicamente, um \emph{grafo (direcionado)}
\index{grafo}%
\index{grafo direcionado}%
é um par
$G=(V,E)$ onde
$V$ é um conjunto de \emph{vértices}
\index{vértice}%
e $E$ é um conjunto de pares ordenados de vértices chamados de 
\emph{arestas}.
\index{aresta}%
Uma aresta #(i,j)# é \emph{direcionada}
\index{aresta direcionada}%
de #i# para #j#;  #i# é chamado de \emph{origem}
\index{origem}, ou \emph{source} em inglês, da aresta e #j#
é chamado de destino, ou \emph{target} em inglês.
\index{target}  Um caminho, \emph{path},%
\index{path} em $G$ é uma sequência de vértices 
$v_0,\ldots,v_k$ tal que, para todo $i\in\{1,\ldots,k\}$,
a aresta $(v_{i-1},v_{i})$ está em $E$.  Um caminho $v_0,\ldots,v_k$ é um
\emph{ciclo}
\index{ciclo}%
se, adicionalmente, a aresta
 $(v_k,v_0)$ está em $E$.  Um caminho (ou ciclo) é 
\emph{simples}
\index{caminho/ciclo simples}%
se todos o seus vértices são únicos. Se existir um caminho de algum vértice
$v_i$ para algum vértice $v_j$ então dizemos que 
$v_j$ é \emph{alcançável}
\index{vértice alcançável} de $v_i$.  Um exemplo de um grafo é mostrado na 
\figref{graph}.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/graph}
  \end{center}
  \caption{Um grafo com doze vértices. Vértices são desenhados como círculos numerados e arestas são desenhadas como curvas com setas apontando da origem ao destino.}
  \figlabel{graph}
\end{figure}

Devido à sua habilidade de modelar tantos fenômenos, grafos têm 
um enorme número de aplicações. Existem muitos exemplos óbvios. 
Redes de computadores podem ser modeladas como grafos, com vértices 
correspondentes a computadores e arestas correspondentes a links 
(direcionados) de comunicação entre computadores.
Ruas de cidades podem ser modeladas como grafos, com vértices 
representando cruzamentos e arestas representando ruas.

Exemplos menos óbvios ocorrem assim que percebemos que grafos podem 
modelar qualquer relações que ocorrem em pares de elementos de um conjunto.
Por exemplo, em uma universidade podemos ter um \emph{grafo de conflitos} de horários
\index{grafo de conflitos} cujos vértices representam cursos oferecidos em uma 
universidade no qual a aresta #(i,j)# está presente se e somente se existe pelo 
menos um estudante que está frequentando a disciplina #i# e a disciplina #j#.
Então, uma aresta indica que a prova para a disciplina #i# não pode ser
agendada no mesmo horário que o exame para a disciplina #j#.

Ao longo dessa seção, iremos usar #n# para denotar o número de vértices
de $G$ e #m# para denotar o número de arestas de $G$. Isto é, 
$#n#=|V|$ e
$#m#=|E|$. Além disso, assumiremos que $V=\{0,\ldots,#n#-1\}$.
Outros dados que gostaríamos de associar com os elementos de $V$
podem ser guardados em um array de tamanho $#n#$.

Algumas operações típicas realizadas em grafos são:
\begin{itemize}
  \item #addEdge(i,j)#: Adicionar a aresta $(#i#,#j#)$ a $E$.
  \item #removeEdge(i,j)#: Remover a aresta $(#i#,#j#)$ de $E$.
  \item #hasEdge(i,j)#: Verificar se a aresta $(#i#,#j#)\in E$ 
  \item #outEdges(i)#: Retornar uma #List# de todos os inteiros $#j#$ tais que
  $(#i#,#j#)\in E$
  \item #inEdges(i)#: Retornar uma #List# de todos os inteiros $#j#$ tais que 
  $(#j#,#i#)\in E$
\end{itemize}

Note que essas operações não são terrivelmente difíceis de implementar eficientemente. 
Por exemplo, as três primeiras operações podem ser implementadas diretamente 
usando um #USet#, de forma que podem ser implementadas em tempo esperado constante 
usando tabelas hash discutidas no \chapref{hashing}.
As duas últimas operações podem ser implementadas em tempo constante 
guardando, para cada vértice, uma lista de seu vértices adjacentes.

Entretanto, diferentes aplicações de grafos têm diferentes exigências de desempenho 
para essas operações e, idealmente, podemos usar a implementação 
mais simples que satisfaz todos os requisitos da aplicação.
Devido essa razão, nós discutimos duas grandes categorias de representações
de grafos.

\section{#AdjacencyMatrix#: Representando um Grafo com um Matriz}
\seclabel{adjacency-matrix}

\index{matriz de adjacências}%
Uma \emph{matriz de adjacências} é uma forma de representar um grafo com #n# vértices 
$G=(V,E)$ com uma matriz $#n#\times#n#$, #a#, cujas entradas são valores booleanos. 
\codeimport{ods/AdjacencyMatrix.a.n.AdjacencyMatrix(n0)}

A valor da matriz #a[i][j]# é definido como 
\[  #a[i][j]#= 
    \begin{cases}
      #true# & \text{se $#(i,j)#\in E$} \\
      #false# & \text{caso contrário}
    \end{cases}
\]

A matriz de adjacências para o grafo na \figref{graph} é mostrado na 
\figref{graph-adj}.

Nessa representação, as operações 
#addEdge(i,j)#,
#removeEdge(i,j)# e #hasEdge(i,j)# somente atribuem e lêem a entrada
da matriz
#a[i][j]#:
\codeimport{ods/AdjacencyMatrix.addEdge(i,j).removeEdge(i,j).hasEdge(i,j)}
Essas operações claramente levam tempo constante por operação. 

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/graph} \\[3ex]
    \begin{tabular}{c|cccccccccccc}
        &0&1&2&3&4&5&6&7&8&9&10&11 \\\hline
       0&0&1&0&0&1&0&0&0&0&0&0 &0\\
       1&1&0&1&0&0&1&1&0&0&0&0 &0\\
       2&1&0&0&1&0&0&1&0&0&0&0 &0\\
       3&0&0&1&0&0&0&0&1&0&0&0 &0\\
       4&1&0&0&0&0&1&0&0&1&0&0 &0\\
       5&0&1&1&0&1&0&1&0&0&1&0 &0\\
       6&0&0&1&0&0&1&0&1&0&0&1 &0\\
       7&0&0&0&1&0&0&1&0&0&0&0 &1\\
       8&0&0&0&0&1&0&0&0&0&1&0 &0\\
       9&0&0&0&0&0&1&0&0&1&0&1 &0\\
      10&0&0&0&0&0&0&1&0&0&1&0 &1\\
      11&0&0&0&0&0&0&0&1&0&0&1 &0\\
    \end{tabular} 
  \end{center}
  \caption{Um grafo e sua matriz de adjacências.}
  \figlabel{graph-adj}
\end{figure}

A matriz de adjacências tem desempenho ruim com as operações
#outEdges(i)# e 
#inEdges(i)#.  Para implementá-las, precisamos varrer todas as #n# entradas na correspondente linha ou coluna de #a# e reunir todos os índices #j# 
onde #a[i][j]#, respectivamente #a[j][i]#, seja verdadeiro.
\javaimport{ods/AdjacencyMatrix.outEdges(i).inEdges(i)}
\cppimport{ods/AdjacencyMatrix.outEdges(i,edges).inEdges(i,edges)}
Essas operações claramente levam $O(#n#)$ de tempo por operação. 

Outra desvantagem da matriz de adjacências é o seu tamanho. Ela guarda
uma matriz booleana de tamanho $#n#\times #n#$, o que exige o uso de pelo 
menos $#n#^2$ bits de memória.   A implementação aqui usa uma matriz de 
valores \javaonly{#boolean#}\cpponly{#bool#} tal que ela na verdade usa na ordem de 
$#n#^2$ bytes de memória.  Uma implementação mais cuidadosa, que empacota 
#w# valores booleanos em cada palavra de memória, poderia reduzir esse 
uso de espaço a $O(#n#^2/#w#)$ palavras de memória.

\begin{thm}
  A estrutura de dados #AdjacencyMatrix# implementa a interface #Graph#.
Uma #AdjacencyMatrix# possui as operações 
\begin{itemize}
  \item #addEdge(i,j)#, #removeEdge(i,j)# e #hasEdge(i,j)# em tempo
    constante por operação; e 
  \item #inEdges(i)# e #outEdges(i)# em $O(#n#)$ tempo por operações.
\end{itemize}
O espaço usado por uma #AdjacencyMatrix# é $O(#n#^2)$.
\end{thm}

Apesar de alto uso de memória e desempenho ruim das operações 
 #inEdges(i)#
e #outEdges(i)#, uma #AdjacencyMatrix# pode ainda ser útil para
algumas aplicações. Em especial, quando o grafo $G$ é \emph{denso},
ele tem quase $#n#^2$ arestas, então um uso de memória de $#n#^2$ pode
 ser aceitável. 

A estrutura de dados #AdjacencyMatrix# também é frequentemente usada
porque operações algébricas na matriz #a# podem ser usadas para computar
eficientemente as propriedades do grafo $G$. 
Isso é um tópico para uma disciplina sobre algoritmos, mas uma dessas
propriedades é: se tratarmos as entradas de #a# como inteiros (1 para #true# e 0 para
#false#) e multiplicarmos #a# por si mesma usando multiplicação de matrizes
então obtemos a matriz 
$#a#^2$.  Lembre-se, da definição de multiplicação de matrizes, que 
\[
    #a^2[i][j]# = \sum_{k=0}^{#n#-1} #a[i][k]#\cdot #a[k][j]# \enspace .
\]
Interpretando essa soma em termos do grafo $G$, essa fórmula conta o
número de vértices, $#k#$, tal que $G$ contém as arestas #(i,k)#
e #(k,j)#.  Isto é, isso conta o número de caminhos de $#i#$ a $#j#$
(por meio de vértices intermediários, $#k#$) cujo comprimento é exatamente dois.
Essa observação é a fundação de um algoritmo que computa os caminhos
mais curtos entre todos os pares de vértices em 
$G$ usando somente $O(\log
#n#)$ multiplicações de matrizes.

\section{#AdjacencyLists#: Um Grafo como uma Coleção de Listas}
\seclabel{adjacency-list}

\index{listas de adjacências}%
Representações de grafos usando \emph{listas de adjacências} é uma abordagem centrada nos vértices.
Existem muitas implementações possíveis de listas de adjacências.
Nesta seção, apresentamos uma simples. No final da seção, discutimos
diferentes possibilidades. Em uma representação de listas de adjacências,
o grafo $G=(V,E)$ é representado como um array #adj# de listas. A lista 
#adj[i]# contém uma lista de vértices adjacentes ao vértice #i#.
Isto é, ela contém todo índice #j# tal que $#(i,j)#\in E$.
\codeimport{ods/AdjacencyLists.adj.n.AdjacencyLists(n0)}
(Uma exemplo é mostrado na \figref{graph-adjlist}.)  
Nessa implementação em especial, representamos cada lista em #adj# como 
\javaonly{uma}\cpponly{uma 
subclasse de} #ArrayStack#, porque gostaríamos acesso pela posição 
em tempo constante.
Especificamente, poderíamos implementar #adj# como uma #DLList#.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/graph} \\[3ex]
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}\hline
        0&1&2&3&4&5&6 &7 &8&9 &10&11 \\\hline
        1&0&1&2&0&1&5 &6 &4&8 &9 &10 \\
        4&2&3&7&5&2&2 &3 &9&5 &6 &7 \\
         &6&6& &8&6&7 &11& &10&11& \\
         &5& & & &9&10&  & &  &  & \\
         & & & & &4&  &  & &  &  & \\
    \end{tabular} 
  \end{center}
  \caption{Uma grafo e suas listas de adjacência.}
  \figlabel{graph-adjlist}
\end{figure}

A operação
#addEdge(i,j)# simplesmente acrescenta o valor #j# no final da lista #adj[i]#:
\codeimport{ods/AdjacencyLists.addEdge(i,j)}
Isso leva tempo constante.

A operação #removeEdge(i,j)# busca ao longo da lista #adj[i]#
até que ache #j# e então o remove:
\codeimport{ods/AdjacencyLists.removeEdge(i,j)}
Isso leva $O(\deg(#i#))$ de tempo, onde $\deg(#i#)$ (o \emph{grau}
\index{grau}%
de $#i#$) conta o número de arestas em $E$ que têm $#i#$ como origem.

A operação
#hasEdge(i,j)# é similar: ela busca ao longo da lista 
#adj[i]# até achar #j# (e retorna true), ou chega no final da lista (e retorna false): 
\codeimport{ods/AdjacencyLists.hasEdge(i,j)}
Isso também leva $O(\deg(#i#))$ de tempo.

A operação #outEdges(i)# é bem simples: 
\pcodeonly{retorna a lista #adj[i]#}
\javaonly{retorna a lista #adj[i]#}
\cpponly{copia os valores em #adj[i]# em uma lista de saída}:
\pcodeimport{ods/AdjacencyLists.outEdges(i)}
\javaimport{ods/AdjacencyLists.outEdges(i)}
\cppimport{ods/AdjacencyLists.outEdges(i,edges)}
\javaonly{Isso claramente leva tempo constante.}\cpponly{Isso leva $O(\deg(#i#))$ de tempo.}

A operação #inEdges(i)# é muito mais trabalhosa. Ela varre 
todo vértice $j$ verificando se a aresta #(i,j)# existe e, 
caso positivo, adiciona #j# a uma lista de saída:
\pcodeimport{ods/AdjacencyLists.inEdges(i)}
\javaimport{ods/AdjacencyLists.inEdges(i)}
\cppimport{ods/AdjacencyLists.inEdges(i,edges)}
Essa operação é muito lenta. Ela verifica toda lista de adjacência de todos 
os vértices, então leva $O(#n# + #m#)$ de tempo.

O teorema a seguir resume o desempenho das estruturas de dados anteriormente descrita:

\begin{thm}
A estrutura de dados #AdjacencyLists# implementa a interface #Graph#.
Uma #AdjacencyLists# possui as operações 
\begin{itemize}
  \item #addEdge(i,j)# em tempo constante por operação; 
  \item #removeEdge(i,j)# e #hasEdge(i,j)# em tempo $O(\deg(#i#))$ por operação; 
  \javaonly{\item #outEdges(i)# em tempo constante por operação; e}
  \cpponly{\item #outEdges(i)# em $O(\deg(#i#))$ de tempo por operação; e}
  \item #inEdges(i)# em $O(#n#+#m#)$ de tempo por operação.
\end{itemize}
O espaço usado por uma #AdjacencyLists# é $O(#n#+#m#)$.
\end{thm}

Conforme mencionado anteriormente, existem muitas escolhas que
podem ser feitas ao implementar um grafo como listas de adjacências. Algumas
escolhas incluem:
\begin{itemize}
  \item Que tipo de coleção deve ser usada para guardar cada elemento de 
  #adj#?  Podem ser usadas uma listas baseadas em arrays, listas ligadas ou mesmo tabelas hash.
  \item Deve haver uma segunda lista de adjacência, #inadj#, que guarda para cada #i#, a lista de vértices, #j#, tal que $#(j,i)#\in E$?
  Isso pode reduzir enormemente o tempo de execução da operação
  #inEdges(i)#, mas requer ligeiramente mais trabalho ao adicionar ou remover arestas. 
\item A entrada para a aresta #(i,j)# na #adj[i]# deve ser ligada por uma referência à entrada correspondente entrada em #inadj[j]#?
\item Arestas devem ser objetos de primeira classe com seus próprios dados associados? Dessa maneira, #adj# conteria listas de arestas em vez de listas de vértices (inteiros).
\end{itemize}
A maior parte dessas questões resultam em um balanço entre complexidade (e espaço) de implementação e características de desempenho da implementação. 

\section{Travessia em Grafos}

Nesta seção, apresentamos dois algoritmos para explorar um grafo, 
iniciando em um de seus vértices #i# e encontrando todos os vértices 
que são alcançáveis a partir de #i#. Esses dois algoritmos são mais 
adequados para grafos representação usando listas de adjacências. 
Portanto, ao analisar esses algoritmos iremos supor que a representação é uma 
#AdjacencyLists#.

\subsection{Busca em Largura}

\index{breadth-first-search}%
\index{busca em largura}%
O algoritmo de \emph{busca em largura} inicia-se em um vértice #i# e visita primeiramente os vizinhos de #i# e, então, os vizinhos dos vizinhos de #i# e depois os vizinhos dos vizinhos dos vizinhos de #i# e assim por diante. 

Esse algoritmo é uma generalização do algoritmo de travessia em 
largura para árvores binárias (\secref{bintree:traversal}), e é muito similar a ele;
utiliza-se uma queue, #q#, que inicialmente contém somente #i#.
Então repetidamente extrai um elemento de #q# e adiciona seus 
vizinhos a #q#, dado que esses vizinhos nunca estiveram em #q# antes.
A maior diferença entre o algoritmo de busca em largura para grafos 
e o de árvores é que o algoritmo para grafos tem que garantir 
que não vai adicionar o mesmo vértice a #q# mais de uma vez.

Isso é feito usando um array booleano auxiliar, #seen# (vistos, em português), 
que guarda quais vértices foram descobertos até o momento.
\codeimport{ods/Algorithms.bfs(g,r)}
Um exemplo de execução
 #bfs(g,0)# no grafo da \figref{graph}
é mostrado na \figref{graph-bfs}.  Execuções diferentes são possíveis, dependendo da ordem das listas de adjacências; a 
\figref{graph-bfs} usa as listas de adjacências da \figref{graph-adjlist}.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/graph-bfs}
  \end{center}
  \caption[Busca em largura]{Um exemplo de busca em largura iniciando no nodo 0. Nodos são marcados com a ordem em que eles são adicionados a #q#. Arestas que resultam em nodos sendo adicionados a #q# são desenhados em preto, outras arestas são desenhadas em cinza.} 
  \figlabel{graph-bfs}
\end{figure}

Analisar o tempo de execução da rotina #bfs(g,i)# é razoavelmente fácil.
O uso do array #seen# assegura que nenhum vértice é 
adicionado a #q# mais de uma vez. Adicionar (e depois remover) 
cada vértice de #q# leva tempo constante por vértice, levando a um total de tempo 
$O(#n#)$.
Como cada vértice é processado pelo laço interno no máximo uma vez, 
cada lista de adjacência é processada no máximo uma vez, então cada aresta de 
$G$ é processada somente uma vez.
Esse processamento, que é feito pelo laço interno, leva tempo constante por iteração, totalizando em 
$O(#m#)$ de tempo. Portanto, o algoritmo por inteiro roda em
$O(#n#+#m#)$ de tempo.

O teorema a seguir resume o desempenho do algoritmo 
 #bfs(g,r)#.
\begin{thm}\thmlabel{bfs-graph}
  O algoritmo #bfs(g,r)# roda, em um #Graph# #g# implementado usando
  a estrutura de dados #AdjacencyLists#, em tempo $O(#n#+#m#)$. 
\end{thm}

Uma travessia em largura tem algumas propriedades especiais. 
Chamar #bfs(g,r)# irá eventualmente enfileirar 
(eventualmente desenfileirar) todo vértice
#j#, tal que existe um caminho direto de #r# para #j#.
Além disso, os vértices com distância 0 a partir de #r# (o próprio #r#) irá entrar em #q# antes dos vértices com distância 1, que entrarão em #q# antes dos vértices com distância 2 e assim por diante. Portanto, 
o método #bfs(g,r)# visita vértices em ordem crescente de distância de #r# e os vértices que não podem ser alcançados a partir de #r# nunca serão visitados. 

Uma aplicação especialmente útil do algoritmo de busca em largura é, portanto,
na computação dos menores caminhos.
Para computar o menor caminho de #r# a todo outro vértice, usamos uma variante de
#bfs(g,r)# que usa um array auxiliar #p# de comprimento #n#.
Quando um novo vértice #j# é adicionado a #q#, fazemos #p[j] =i#. Dessa forma, #p[j]# se torna o penúltimo nodo no caminho mais curto de #r# a #j#. 
Ao repetir isso fazendo 
#p[p[j]]#, #p[p[p[j]]]# e assim por diante podemos reconstruir 
o caminho mais curto (invertido) de #r# a #j#. 

\subsection{Busca em Profundidade}

O algoritmo de \emph{busca em profundidade}
\index{busca em profundidade}%
é similar ao algoritmo padrão para percorrer árvores binárias;
ele primeiro explora completamente uma subárvore antes de retornar 
ao nodo atual e então explora outra subárvore. Outra forma de 
pensar na busca em profundidade é dizer que é similar 
à busca em largura exceto que ele usa uma pilha em vez de uma fila.

Durante a execução do algoritmo de busca em profundidade, cada vértice #i# 
é atribuído a uma cor #c[i]#: #white# se nunca encontramos o vértice antes
#grey# se estamos visitando o vértice e #black# se terminamos de visitar o vértice.
O jeito mais fácil de pensar da busca em profundidade é 
na forma de um algoritmo recursivo. Ele inicia com uma visita a #r#. 
Ao visitar um vértice #i#, primeiro 
marcamos #i# como #cinza#. Depois, varremos a lista de adjacência 
de #i# e recursivamente visitamos qualquer vértice branco que não achamos nessa lista.
Finalmente, terminamos o processamento de #i# e então pintamos #i# de preto e retornamos.

\codeimport{ods/Algorithms.dfs(g,r).dfs(g,i,c)}
Um exemplo da execução desse algoritmo é mostrado na \figref{graph-dfs}.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/graph-dfs}
  \end{center}
  \caption[Busca em profundidade]{Um exemplo da busca em profundidade iniciando no nodo 0. Nodos são marcados com a ordem em que são processados. Arestas que resultam em uma chamada recursiva são desenhados em preto, outras arestas são desenhadas em cinza.}
  \figlabel{graph-dfs}
\end{figure}

Embora a busca em profundidade possa ser melhor pensada como um algoritmo recursivo,
usar recursão não é a melhor forma de implementá-la. 
Realmente, o código dado acima irá falhar para grafos grandes causando
uma estouro da pilha de memória, um \emph{stack overflow}.
Uma implementação alternativa troca a pilha de recursão 
por uma pilha explícita #s#.
A implementação a seguir faz exatamente isso:
\codeimport{ods/Algorithms.dfs2(g,r)} 
No código anterior, quando o vértice a seguir #i# é processado, #i# é pintado
de #grey# e então substituído na pilha com seus vértices adjacentes. 
Durante a próxima iteração, um desses vértices será visitado.

Pouco surpreendentemente, os tempos de execução de 
#dfs(g,r)# e #dfs2(g,r)# são os mesmos que os de 
#bfs(g,r)#:
\begin{thm}\thmlabel{dfs-graph}
Ao processar um #Graph# g que é implementado usando a estrutura de dados 
  #AdjacencyLists#, os algoritmos #dfs(g,r)# e #dfs2(g,r)# 
  rodam em tempo $O(#n#+#m#)$.
\end{thm}

De modo similar ao algoritmo de busca em largura, existe uma árvore associada com cada
 execução da busca em profundidade. Quando um nodo 
$#i#\neq #r#$ vai de #white# a #grey#, é porque #dfs(g,i,c)#
foi chamado recursivamente ao processar algum nodo #i'#. (No caso do algoritmo 
#dfs2(g,r)#, #i# é um dos nodos que substituem #i'# na pilha.) 
Se pensarmos de #i'# como o pai de #i#, então obtemos uma árvore enraizada em #r#.
Na \figref{graph-dfs}, essa árvore é um caminho do vértice 0 ao vértice 11. 

Uma propriedade importante do algoritmo de busca em profundidade é a seguinte:
suponha que quando um nodo #i# é pintado de #grey#, existe um caminho de #i#
a algum outro nodo #j# que usa somente vértices brancos. Então #j#
será pintado primeiro de #grey# e depois de #preto# antes 
que #i# seja pintado de #black#.
(Isso pode ser provado por contradição, ao considerar 
qualquer caminho $P$ de #i# para #j#.)

Uma aplicação dessa propriedade é a detecção de ciclos.
\index{detecção de ciclos}%
Veja a 
\figref{dfs-cycle}.  Considere algum ciclo $C$, que pode ser
alcançado a partir de #r#. Seja #i# o primeiro nodo de $C$ 
que é pintado de #grey# e seja
#j# o nodo que precede #i# no ciclo $C$.
Então, pela propriedade acima, #j# será pintado de #grey# e a aresta #(j,i)#
será considerada pelo algoritmo enquanto #i# ainda for #grey#. Portanto,
o algoritmo pode concluir que existe um caminho $P$ partindo de #i# a #j#
na árvore de busca em profundidade e que a aresta 
#(j,i)# existe. Portanto, $P$ também é um ciclo. 

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/dfs-cycle}
  \end{center}
  \caption[Detecção de ciclos]{O algoritmo de busca em profundidade pode 
  ser usado para detectar ciclos em $G$. O nodo #j# está #grey# 
  enquanto #i# ainda for #grey#. Isso implica que existe um caminho $P$ 
  de $i$ a $j$ na árvore de busca em profundidade e a aresta 
  #(j,i)# implica que $P$ também é um ciclo.}
  \figlabel{dfs-cycle}
\end{figure}

\section{Discussão e Exercícios}

Os tempos de execução dos algoritmos da busca em profundidade e da busca em largura
são de certa forma exagerados pelos Teoremas~\ref{thm:bfs-graph} e
\ref{thm:dfs-graph}. Defina $#n#_{#r#}$ como sendo o número de 
vértices #i# de $G$ para os quais existem um caminho de #r# a #i#. 
Defina $#m#_#r#$ como o número de arestas que têm esses
vértices como suas origens.
Então o teorema a seguir é mais preciso na descrição dos tempos
de execução dos algoritmos de busca em largura e em profundidade.
(Esse teorema mais preciso do tempo de execução é útil em algumas 
das aplicações descritas nos exercícios deste capítulo.)
\begin{thm}\thmlabel{graph-traversal}
Ao processar um 
  #Graph#, #g#, que é implementado usando a estrutura de dados 
  #AdjacencyLists#, os algoritmos #bfs(g,r)#, #dfs(g,r)# e #dfs2(g,r)#
  rodam em tempo $O(#n#_{#r#}+#m#_{#r#})$.
\end{thm}

Busca em largura parece ter sido descoberta independentemente por 
Moore \cite{m59} e Lee \cite{l61} nos contextos de exploração de 
labirintos e roteamento de circuitos, respectivamente. 

Representações de grafos baseadas em listas de adjacências foram propostas
por Hopcroft e Tarjan \cite{ht73} como uma alternativa à 
(então mais comum) representação baseada em matriz de adjacências.
Essa representação, assim como busca em profundidade, desempenhou 
um papel importante no famoso algoritmo de teste de planaridade de Hopcroft-Tarjan
\index{teste de planaridade}%
que pode determinar, em tempo $O(#n#)$ se um grafo pode ser 
desenhado no plano de forma que nenhum par de arestas se cruzem \cite{ht74}.

Nos exercícios a seguir, um grafo não direcionado é um em que, para todo
#i# e #j#, a aresta 
$(#i#,#j#)$ existe se e somente se a aresta 
$(#j#,#i#)$ existe.
\index{grafo não direcionado}%
\index{grafo!não direcionado}%

\begin{exc}
  Desenhe uma representação baseada em uma lista de adjacências e uma 
  baseada em matriz de adjacências do grafo na \figref{graph-example2}.
\end{exc}

\begin{figure}
  \centering{\includegraphics[scale=0.90909]{figs/graph-example2}}
  \caption{Um exemplo de grafo.}
  \figlabel{graph-example2}
\end{figure}

\begin{exc}
  \index{matriz de incidência}%
A representação baseada em \emph{matriz de incidência} de um grafo,
  $G$, é uma $#n#\times#m#$ matriz, $A$, onde
  \[
     A_{i,j} = \begin{cases}
        -1 & \text{se o vértice $i$ for a origem da aresta para $j$} \\
        +1 & \text{se o vértice $i$ for o destino da aresta iniciada em $j$} \\
        0 & \text{caso contrário.}
     \end{cases}
  \]
  \begin{enumerate}
    \item Desenhe a representação baseada em matriz de incidência do grafo na
      \figref{graph-example2}.
    \item Projete, analise e implemente uma representação baseada em matriz de incidência de um grafo. Analise o custo de espaço e o custo de tempo das operações 
      #addEdge(i,j)#, #removeEdge(i,j)#, #hasEdge(i,j)#, #inEdges(i)#
      e #outEdges(i)#.
  \end{enumerate}
\end{exc}

\begin{exc}
  Desenhe uma execução do algoritmos
  #bfs(G,0)# e #dfs(G,0)# no grafo $#G#$
  da \figref{graph-example2}.
\end{exc}

\begin{exc}
  \index{grafo conectado}%
  \index{graph!connected}%
  Seja um grafo não direcionado $G$.  Dizemos que $G$ é \emph{conectado} se,
para todo par de vértices #i# e #j# em $G$, existe um caminho de 
  $#i#$ a $#j#$ (como $G$ não é direcionado, também existe um caminho de #j# a #i#).
  Mostre como testar se $G$ é conectado em tempo $O(#n#+#m#)$.
\end{exc}

\begin{exc}
  \index{componentes conectados}%
  Seja $G$ um grafo não direcionado. \emph{Marcações de componentes conectados} (em inglês, \emph{connected-component labelling}) de $G$ particiona os vértices de $G$ em conjuntos maximais, cada qual forma um subgrafo conectado. Mostre como computar as marcações de componentes conectados de $G$ em 
  $O(#n#+#m#)$ de tempo.
\end{exc}

\begin{exc}
  \index{floresta geradora}%
  Seja $G$ um grafo não direcionado.  Uma \emph{floresta geradora} de $G$ é uma coleção de árvores, uma por componente, cujas arestas são arestas de $G$
  e cujos vértices contêm todos os vértices de $G$. Mostre como computar
  uma floresta geradora de $G$ em $O(#n#+#m#)$ de tempo. 
\end{exc}

\begin{exc}
  \index{grafo fortemente contectado}%
  \index{grafo!fortemente conectado}%
  Dizemos que um grafo $G$ é \emph{fortemente conectado} se, para todo
  par de vértices #i# e #j# em $G$, existir um caminho de 
  $#i#$ para
  $#j#$. Mostre como testar se $G$ é fortemente conectado em $O(#n#+#m#)$ de tempo. 
\end{exc}

\begin{exc}
Dado um grafo $G=(V,E)$ e algum vértice especial $#r#\in V$, mostre como
  computar o comprimento do caminho mais curto a partir de 
  $#r#$ para #i# para todo vértice $#i#\in V$.
\end{exc}

\begin{exc}
  Ache um exemplo (simples) em que o código #dfs(g,r)# visita os
  nodos de um grafo em uma ordem que é diferente daquela 
  do código do algoritmo #dfs2(g,r)#.
  Escreva uma versão de 
  #dfs2(g,r)# que sempre visita nodos exatamente na mesma ordem 
  que #dfs(g,r)#.  (Dica: simplesmente inicie verificando a execução de cada algoritmo em algum grafo onde #r# é a fonte de mais de 1 aresta.) 
\end{exc}

\begin{exc}
  \index{universal sink}%
  \index{celebridade|see{universal sink}}%
  Uma \emph{universal sink} em um grafo $G$ é um vértice que é o alvo de 
  $#n#-1$ arestas e a origem de nenhuma aresta. \footnote{Uma universal sink,
  #v#, é também às vezes chamada de \emph{celebridade}: Todos na sala reconhecem 
  #v#, mas #v# não reconhece ninguém na sala.} 
  Projete e implemente um algoritmo que testa se um grafo $G$, representado por
  uma #AdjacencyMatrix#, tem uma \emph{universal sink}.  
  O seu algoritmo deve rodar em $O(#n#)$ de tempo.
\end{exc}

